{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GitAudioEmotion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qerI8Kh8hpEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/IEMOCAP_full_release.7z' '/content/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S1PhQVziOtB",
        "colab_type": "text"
      },
      "source": [
        "***UNZIP THE IMOCAP DATASETS***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOm3xEnhiKgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!p7zip -d '/content/IEMOCAP_full_release.7z'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojofRy8zS0Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5rruwKFiX0x",
        "colab_type": "text"
      },
      "source": [
        "*PREPROCESIING THE IMPCAP AUDIO FILES* : THANKS TO ***https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb  and https://github.com/david-yoon/multimodal-speech-emotion/blob/master/preprocessing/IEMOCAP_01_wav_to_feature.ipynb "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmyifjHXii-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from matplotlib.backend_bases import RendererBase\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from scipy.fftpack import fft\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from tensorboardX import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wan_pCAlZj7",
        "colab_type": "text"
      },
      "source": [
        "**read the all the files in a list at sentence level**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkcz86elmCv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import chardet\n",
        "\n",
        "def file_search(dirname, ret, list_avoid_dir=[]):\n",
        "    filenames = os.listdir(dirname)\n",
        "    \n",
        "    for filename in filenames:\n",
        "        full_filename = os.path.join(dirname, filename)\n",
        "\n",
        "        if os.path.isdir(full_filename) :\n",
        "            if full_filename.split('/')[-1] in list_avoid_dir:\n",
        "                continue\n",
        "            else:\n",
        "                file_search(full_filename, ret, list_avoid_dir)\n",
        "            \n",
        "        else:\n",
        "            ret.append( full_filename ) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RToQ2If_lIbO",
        "colab_type": "code",
        "outputId": "131b4e31-bd23-4e17-cd2f-b7d73118622b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "list_files = []\n",
        "for x in range(5):\n",
        "    sess_name = 'Session' + str(x+1)\n",
        "    path = '/content/IEMOCAP_full_release/'+ sess_name + '/sentences/wav/'\n",
        "    file_search(path, list_files)\n",
        "    list_files = sorted(list_files)\n",
        "    print (sess_name + \", #sum files: \" + str(len(list_files)))\n",
        "#extract_feature( list_files, out_file )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Session1, #sum files: 1820\n",
            "Session2, #sum files: 3633\n",
            "Session3, #sum files: 5769\n",
            "Session4, #sum files: 7873\n",
            "Session5, #sum files: 10043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKP6PwqvILJT",
        "colab_type": "text"
      },
      "source": [
        "***below code is:***\n",
        "https://github.com/Escanor1996/Speech-Emotion-Recognition-SER-/blob/master/SER.ipynb\n",
        "\n",
        "***Paper:*** Attention Based Fully Convolutional Network for Speech Emotion Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788jVVFCH7vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def audio2spectrogram(filepath):\n",
        "    #fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    #print('samplerate',samplerate)\n",
        "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
        "    #print(spectrogram.shape)\n",
        "    #print(type(spectrogram))\n",
        "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
        "    return spectrogram\n",
        "    \n",
        "def audio2wave(filepath):\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    samplerate, test_sound  = wavfile.read(filepath,mmap=True)\n",
        "    plt.plot(test_sound)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkiYHO6MH3Kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_specgram(audio, sample_rate, window_size=40,\n",
        "                 step_size=20, eps=1e-10):\n",
        "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
        "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
        "    #print('noverlap',noverlap)\n",
        "    #print('nperseg',nperseg)\n",
        "    freqs, _, spec = signal.spectrogram(audio,\n",
        "                                    fs=sample_rate,\n",
        "                                    window='hann',\n",
        "                                    nperseg=nperseg,\n",
        "                                    noverlap=noverlap,\n",
        "                                    detrend=False)\n",
        "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv66rHV3pLkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_CHANNELS = 3\n",
        "def get_3d_spec(Sxx_in, moments=None):\n",
        "    if moments is not None:\n",
        "        (base_mean, base_std, delta_mean, delta_std,\n",
        "             delta2_mean, delta2_std) = moments\n",
        "    else:\n",
        "        base_mean, delta_mean, delta2_mean = (0, 0, 0)\n",
        "        base_std, delta_std, delta2_std = (1, 1, 1)\n",
        "    h, w = Sxx_in.shape\n",
        "    right1 = np.concatenate([Sxx_in[:, 0].reshape((h, -1)), Sxx_in], axis=1)[:, :-1]\n",
        "    delta = (Sxx_in - right1)[:, 1:]\n",
        "    delta_pad = delta[:, 0].reshape((h, -1))\n",
        "    delta = np.concatenate([delta_pad, delta], axis=1)\n",
        "    right2 = np.concatenate([delta[:, 0].reshape((h, -1)), delta], axis=1)[:, :-1]\n",
        "    delta2 = (delta - right2)[:, 1:]\n",
        "    delta2_pad = delta2[:, 0].reshape((h, -1))\n",
        "    delta2 = np.concatenate([delta2_pad, delta2], axis=1)\n",
        "    base = (Sxx_in - base_mean) / base_std\n",
        "    delta = (delta - delta_mean) / delta_std\n",
        "    delta2 = (delta2 - delta2_mean) / delta2_std\n",
        "    stacked = [arr.reshape((h, w, 1)) for arr in (base, delta, delta2)]\n",
        "    return np.concatenate(stacked, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMNBRvIxRfUc",
        "colab_type": "text"
      },
      "source": [
        "Spectrogram: one axis represents the time(X-axis), the second axis represents frequencies(Y-axis) and the colors represent magnitude (amplitude) of the observed frequency at a particular time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCQegmJSYX-T",
        "colab_type": "text"
      },
      "source": [
        "***read the processed transcription file to collect the labels***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmXOncwLSThg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel('/content/drive/My Drive/Imocap_text/processed_tran.xlsx')\n",
        "#filename=list_files[60].split('/')[-1].strip('.wav')\n",
        "#lable=df.loc[df['sessionID']==filename]['label'].values[0]\n",
        "#if(lable!=-1):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atR-YPWjneVs",
        "colab_type": "text"
      },
      "source": [
        "***EXTACT THE MFCC FEATURE USING LIBROSA***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsY4d9gPm3lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_rows=len(list_files)\n",
        "index=0\n",
        "sprectrogram_shape=[]\n",
        "docs = []\n",
        "bookmark=0\n",
        "extraLabel=0\n",
        "for everyFile in list_files:\n",
        "  if(everyFile.split('/')[-1].endswith('.wav')):\n",
        "    filename=everyFile.split('/')[-1].strip('.wav')\n",
        "    lable=df.loc[df['sessionID']==filename]['label'].values[0]\n",
        "    print('label',lable)\n",
        "    if(lable!=-1):\n",
        "      #sprectrogram_shape.append(audio2spectrogram(everyFile))\n",
        "      spector=audio2spectrogram(everyFile)\n",
        "      spector=get_3d_spec(spector)\n",
        "      npimg = np.transpose(spector,(2,0,1))\n",
        "      input_tensor=torch.tensor(npimg)\n",
        "      input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "      #X, sample_rate = librosa.load(everyFile, res_type='kaiser_fast',sr=22050*2)\n",
        "      #sample_rate = np.array(sample_rate)\n",
        "      #mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=13),axis=0)\n",
        "      #feature = mfccs\n",
        "      docs.append({\n",
        "         'fileName':everyFile.split('/')[-1].strip('.wav'),\n",
        "         #'feature_mfcc':feature,\n",
        "         'sprectrome':input_batch,\n",
        "         'label':lable\n",
        "              })\n",
        "      index+=1\n",
        "      print('index',index)\n",
        "    else:\n",
        "      extraLabel=extraLabel+1\n",
        "      print('extraLabel',extraLabel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPnKlxI1PSmO",
        "colab_type": "text"
      },
      "source": [
        "***TestAlexNet input***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij-TYGuMPcjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "#from .utils import load_state_dict_from_url\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((12, 12))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        print('features',x.shape)\n",
        "        \n",
        "        #x = self.avgpool(x)\n",
        "        #print('avgpool',x.shape)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        #print('flatten',x.shape)\n",
        "        #x = self.classifier(x)\n",
        "        return x\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qClksYw-dtb",
        "colab_type": "text"
      },
      "source": [
        "***MOdified AlexNet***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zQEjewO-hLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModifiedAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(ModifiedAlexNet, self).__init__()\n",
        "        self.num_classes=num_classes\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        #print('features',x.shape)\n",
        "        x=torch.flatten(x, start_dim=2)#a1,a2,a3......al{a of dim c} \n",
        "        x=torch.sum(x, dim=2)#a1*alpha1+a2*alpha2+.......+al*alphal\n",
        "        #print(x.shape)\n",
        "        x=self.classifier(x)\n",
        "        #print('classifier',x)\n",
        "        #x=self.softmax(x)\n",
        "        #print('softmax',x)\n",
        "        #x = self.avgpool(x)\n",
        "        #print('avgpool',x.shape)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        #print('flatten',x.shape)\n",
        "        #x = self.classifier(x)\n",
        "        return x\n",
        "   \n",
        "def modifiedAlexNet(pretrained=False, progress=True, **kwargs):\n",
        "    model_modified = ModifiedAlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model_modified.load_state_dict(state_dict)\n",
        "    return model_modified"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBABecl_Gl9N",
        "colab_type": "text"
      },
      "source": [
        "***create the Modified model instance and initiliaze with the pretraine d model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsIPd9oBGvag",
        "colab_type": "code",
        "outputId": "5cd3a187-7234-4f23-e930-34e1f30543bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "original_model=alexnet(pretrained=True)\n",
        "original_dict = original_model.state_dict()\n",
        "modifiedAlexNet=modifiedAlexNet(pretrained=False)\n",
        "modified_model_dict = modifiedAlexNet.state_dict()\n",
        "pretrained_modified_model_dict = {k: v for k, v in original_dict.items() if k in modified_model_dict}\n",
        "modifiedAlexNet.to('cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModifiedAlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=256, out_features=4, bias=True)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ObB4bOBPmA2",
        "colab_type": "text"
      },
      "source": [
        "***Input code to AlexNet with Audio Files***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQxmqNSyTWnr",
        "colab_type": "code",
        "outputId": "0aa1f7c2-e9a3-4633-f7af-e215a86c3a43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x=audio2spectrogram(list_files[40])\n",
        "x=get_3d_spec(x)\n",
        "npimg = np.transpose(x,(2,0,1))\n",
        "input_tensor=torch.tensor(npimg)\n",
        "\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    modifiedAlexNet.to('cuda')\n",
        "with torch.no_grad():\n",
        "    output = modifiedAlexNet(input_batch)\n",
        "    #output.squeeze().shape\n",
        "    #output=torch.flatten(output, start_dim=2)\n",
        "    #print(output.shape)\n",
        "    #output=torch.sum(output, dim=2)\n",
        "    print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-3.6122, -2.7249,  2.3582, -0.5873]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfT1DDnLQg1b",
        "colab_type": "text"
      },
      "source": [
        "***Inputdata schuffling and deviding the data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7JZNzX9QvM3",
        "colab_type": "code",
        "outputId": "9ad46ee4-1d1d-4b2a-9bf4-e180dd50465a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import random\n",
        "random.shuffle(docs)\n",
        "random.shuffle(docs)\n",
        "random.shuffle(docs)\n",
        "total_length=len(docs)\n",
        "train_length=int(.9*total_length)\n",
        "train_list=docs[0:train_length]\n",
        "test_list=docs[train_length:]\n",
        "print('no of items for train ',len(train_list))\n",
        "print('no of items for test ',len(test_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of items for train  4977\n",
            "no of items for test  554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k1pQ5INTvrm",
        "colab_type": "text"
      },
      "source": [
        "***Plot Training loss and Accuracy***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1mv-uS-T2Mo",
        "colab_type": "code",
        "outputId": "b9713c74-8b8b-418c-f9f9-f48e471e0980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 341), started 0:35:43 ago. (Use '!kill 341' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwgNOF5oK-JV",
        "colab_type": "text"
      },
      "source": [
        "***Model Parameter***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzWnvXf5LCIU",
        "colab_type": "code",
        "outputId": "12e2f481-95ed-473e-ebce-25b6474665af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "for name, param in modifiedAlexNet.named_parameters():\n",
        "      if(param.requires_grad):\n",
        "        print(name)\n",
        "      else:\n",
        "        print('no grad',name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.0.weight\n",
            "features.0.bias\n",
            "features.3.weight\n",
            "features.3.bias\n",
            "features.6.weight\n",
            "features.6.bias\n",
            "features.8.weight\n",
            "features.8.bias\n",
            "features.10.weight\n",
            "features.10.bias\n",
            "classifier.1.weight\n",
            "classifier.1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoSuRA4cKeSy",
        "colab_type": "text"
      },
      "source": [
        "***optimizer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_BAUU5kKhAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "from transformers import AdamW\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(modifiedAlexNet.parameters(),\n",
        "                  lr =  2e-4, \n",
        "                  eps = 1e-8\n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "NUM_EPOCHS=16\n",
        "\n",
        "writer = SummaryWriter(log_dir='/content/')\n",
        "total_steps = len(train_list) * NUM_EPOCHS\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYFow8ZlQB67",
        "colab_type": "text"
      },
      "source": [
        "***Training Loop***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hj8xc3LQFDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_steps = 1\n",
        "\n",
        "\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  modifiedAlexNet.train()\n",
        "  for every_trainlist in train_list:\n",
        "    label1=every_trainlist['label']\n",
        "    label1=torch.tensor([label1])\n",
        "    sprectrome=every_trainlist['sprectrome']\n",
        "    if(sprectrome.shape[2]>65):\n",
        "      optimizer.zero_grad()\n",
        "      sprectrome = sprectrome.to('cuda')\n",
        "      label1=label1.to('cuda')\n",
        "      modifiedAlexNet.zero_grad()\n",
        "      output = modifiedAlexNet(sprectrome)\n",
        "      #print('softmax output ',output)\n",
        "      loss = criterion(output, label1)\n",
        "      #print('label1',label1)\n",
        "      #print('loss',loss.item())\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(modifiedAlexNet.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      _, preds = torch.max(output, 1)\n",
        "      accuracy = torch.sum(preds == label1)\n",
        "      #print('accuracy.item()',accuracy.item())\n",
        "      #print('preds',preds)\n",
        "      if total_steps % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "          _, preds = torch.max(output, 1)\n",
        "          accuracy = torch.sum(preds == label1)\n",
        "          #print('Epoch: {} \\tStep: {} \\tLoss: {:.4f} \\tAcc: {}'.format(epoch + 1, total_steps, loss.item(), accuracy.item()))\n",
        "          tbwriter.add_scalar('loss', loss.item(), total_steps)\n",
        "          tbwriter.add_scalar('accuracy', accuracy.item(), total_steps)                     \n",
        "      total_steps+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytSK9YJdzDh2",
        "colab_type": "text"
      },
      "source": [
        "***save and load the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyEVoGs-zHZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(modifiedAlexNet, '/content/drive/My Drive/savedModel/model_audio_new_opt.pt')\n",
        "model=torch.load('/content/drive/My Drive/savedModel/model_audio_new_opt.pt')\n",
        "model.eval()\n",
        "model.to('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfuJ5F0cysjU",
        "colab_type": "text"
      },
      "source": [
        "***testing lopp***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYbcOfizywFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_actu=[]\n",
        "y_pred=[]\n",
        "for every_test_list in test_list:\n",
        "    label1=every_test_list['label']\n",
        "    label1=torch.tensor([label1])\n",
        "    sprectrome=every_test_list['sprectrome']\n",
        "    with torch.no_grad():\n",
        "      if(sprectrome.shape[2]>65):\n",
        "        #sprectrome = sprectrome.to('cuda')\n",
        "        #label1=label1.to('cuda')\n",
        "        output = model(sprectrome)\n",
        "        _, preds = torch.max(output, 1)\n",
        "        y_actu.append(label1.numpy()[0])\n",
        "        y_pred.append(preds.numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNAdE3fQ3z8v",
        "colab_type": "text"
      },
      "source": [
        "***confusionMatrix***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueItzxt432pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_actu, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}